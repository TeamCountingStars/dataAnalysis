import requests
import pandas as pd
import time
from datetime import datetime, timedelta
import os

class GitHubCollector:
    def __init__(self, token):
        """
        GitHub ë°ì´í„° ìˆ˜ì§‘ê¸°
        token: GitHub Personal Access Token
        """
        self.token = token
        self.headers = {
            "Authorization": f"Bearer {token}",
            "Accept": "application/vnd.github+json"
        }
        self.base_url = "https://api.github.com"
    
    def check_rate_limit(self):
        """API ì‚¬ìš©ëŸ‰ í™•ì¸"""
        url = f"{self.base_url}/rate_limit"
        response = requests.get(url, headers=self.headers)
        data = response.json()
        
        remaining = data['rate']['remaining']
        limit = data['rate']['limit']
        reset_time = datetime.fromtimestamp(data['rate']['reset'])
        
        print(f"â±ï¸  ë‚¨ì€ ìš”ì²­: {remaining}/{limit} (ë¦¬ì…‹: {reset_time.strftime('%H:%M:%S')})")
        return remaining
    
    def search_repos(self, keyword, start_date, end_date, per_page=100):
        """ë‹¨ì¼ ë‚ ì§œë¡œ ë ˆí¬ì§€í† ë¦¬ ê²€ìƒ‰"""
        url = f"{self.base_url}/search/repositories"
        query = f"{keyword} created:{start_date}..{end_date}"
        
        params = {
            "q": query,
            "per_page": per_page,
            "sort": "stars",
            "order": "desc",
            "page": 1
        }
        
        all_repos = []
        
        while True:
            response = requests.get(url, headers=self.headers, params=params)
            
            if response.status_code != 200:
                print(f"âŒ ì—ëŸ¬: {response.status_code}")
                break
            
            data = response.json()
            repos = data.get('items', [])
            
            if not repos:
                break
            
            all_repos.extend(repos)
            
            # 1000ê°œ ì œí•œ
            if len(all_repos) >= 1000 or params['page'] >= 10:
                break
            
            params['page'] += 1
            time.sleep(0.5)
        
        return all_repos
    
    def collect_year(self, keywords, year):
        """
        1ë…„ì¹˜ ë°ì´í„° ìˆ˜ì§‘ (ì¼ë³„)
        keywords: ê²€ìƒ‰í•  í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
        year: ìˆ˜ì§‘ ì—°ë„
        """
        all_repos = []
        
        # í‚¤ì›Œë“œë¥¼ ORë¡œ ì—°ê²°
        keyword_string = " OR ".join(keywords)
        
        # ë‚ ì§œ ë²”ìœ„ ì„¤ì •
        start_date = datetime(year, 1, 1)
        end_date = datetime(year, 12, 31)
        
        # 2025ë…„ì€ 11ì›”ê¹Œì§€ë§Œ
        if year == 2025:
            end_date = datetime(2025, 11, 30)
        
        total_days = (end_date - start_date).days + 1
        current_day = 0
        
        print("\n" + "="*70)
        print(f"ğŸ“… {year}ë…„ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
        print(f"ğŸ” í‚¤ì›Œë“œ: {keyword_string}")
        print(f"ğŸ“† ê¸°ê°„: {start_date.strftime('%Y-%m-%d')} ~ {end_date.strftime('%Y-%m-%d')} ({total_days}ì¼)")
        print("="*70)
        
        current_date = start_date
        while current_date <= end_date:
            current_day += 1
            date_str = current_date.strftime("%Y-%m-%d")
            
            print(f"\n[{current_day}/{total_days}] ğŸ” {date_str} ", end="")
            
            repos = self.search_repos(keyword_string, date_str, date_str)
            all_repos.extend(repos)
            
            print(f"â†’ {len(repos)}ê°œ ìˆ˜ì§‘ (ëˆ„ì : {len(all_repos)}ê°œ)")
            
            # Rate Limit ì²´í¬
            remaining = self.check_rate_limit()
            if remaining < 100:
                print("â¸ï¸  API ì œí•œ ì„ë°•. 1ë¶„ ëŒ€ê¸° ì¤‘...")
                time.sleep(60)
            
            current_date += timedelta(days=1)
        
        print("\n" + "="*70)
        print(f"ğŸ‰ {year}ë…„ ìˆ˜ì§‘ ì™„ë£Œ: ì´ {len(all_repos)}ê°œ (ì¤‘ë³µ í¬í•¨)")
        print("="*70)
        
        return all_repos
    
    def repos_to_dataframe(self, repos):
        """ë ˆí¬ì§€í† ë¦¬ ë¦¬ìŠ¤íŠ¸ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜"""
        data = []
        
        for repo in repos:
            data.append({
                'id': repo['id'],
                'name': repo['name'],
                'full_name': repo['full_name'],
                'owner': repo['owner']['login'],
                'owner_type': repo['owner']['type'],
                'description': repo.get('description', ''),
                'language': repo.get('language', 'Unknown'),
                'stars': repo['stargazers_count'],
                'forks': repo['forks_count'],
                'watchers': repo['watchers_count'],
                'open_issues': repo['open_issues_count'],
                'created_at': repo['created_at'],
                'updated_at': repo['updated_at'],
                'pushed_at': repo['pushed_at'],
                'size': repo['size'],
                'url': repo['html_url'],
                'topics': '|'.join(repo.get('topics', [])),
                'license': repo['license']['name'] if repo.get('license') else 'No License',
                'default_branch': repo.get('default_branch', 'main'),
                'has_wiki': repo.get('has_wiki', False),
                'has_pages': repo.get('has_pages', False),
                'archived': repo.get('archived', False)
            })
        
        df = pd.DataFrame(data)
        print(f"\nğŸ“Š DataFrame ìƒì„±: {len(df)}ê°œ ë ˆì½”ë“œ")
        return df
    
    def save_to_csv(self, df, filename):
        """CSVë¡œ ì €ì¥"""
        if not os.path.exists('data'):
            os.makedirs('data')
        
        filepath = os.path.join('data', filename)
        df.to_csv(filepath, index=False, encoding='utf-8-sig')
        
        file_size = os.path.getsize(filepath) / 1024 / 1024
        
        print(f"\nğŸ’¾ ì €ì¥ ì™„ë£Œ!")
        print(f"ğŸ“ ê²½ë¡œ: {os.path.abspath(filepath)}")
        print(f"ğŸ“Š í¬ê¸°: {file_size:.2f} MB")
        print(f"ğŸ“‹ ë ˆì½”ë“œ: {len(df)}ê°œ")
        
        return filepath


# ========== ì‹¤í–‰ ì½”ë“œ ==========

# ğŸ”‘ GitHub Token ì…ë ¥
GITHUB_TOKEN = input("GitHub Tokenì„ ì…ë ¥í•˜ì„¸ìš”: ")

collector = GitHubCollector(GITHUB_TOKEN)

# ì „ì²´ AI í‚¤ì›Œë“œ (ëª¨ë“  ì—°ë„ ë™ì¼)
AI_KEYWORDS = [
    "chatgpt",
    "gpt-4",
    "openai-api",
    "AI-agent",
    "langchain",
    "autonomous-agent",
    "github-copilot",
    "machine-learning",
    "artificial-intelligence",
    "deep-learning",
    "neural-network",
    "llm"
]

# Rate Limit í™•ì¸
collector.check_rate_limit()

# ì—°ë„ë³„ ìˆ˜ì§‘
years = [2021, 2022, 2023, 2024, 2025]

for year in years:
    print(f"\n\n{'='*70}")
    print(f"ğŸ¯ {year}ë…„ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘")
    print(f"{'='*70}")
    
    # ë°ì´í„° ìˆ˜ì§‘
    repos = collector.collect_year(AI_KEYWORDS, year)
    
    # DataFrame ë³€í™˜
    df = collector.repos_to_dataframe(repos)
    
    # ê¸°ë³¸ í†µê³„
    print(f"\nğŸ“Š {year}ë…„ í†µê³„:")
    print(f"  ì´ ë ˆì½”ë“œ: {len(df)}ê°œ")
    print(f"  ê³ ìœ  ë ˆí¬: {df['id'].nunique()}ê°œ")
    print(f"\n  ì–¸ì–´ë³„ Top 5:")
    print(df['language'].value_counts().head())
    
    # CSV ì €ì¥
    filename = f'github_{year}.csv'
    collector.save_to_csv(df, filename)
    
    print(f"\nâœ… {year}ë…„ ì™„ë£Œ!")
    print("\nâ¸ï¸  ë‹¤ìŒ ì—°ë„ ìˆ˜ì§‘ ì „ 10ì´ˆ ëŒ€ê¸°...")
    time.sleep(10)

print("\n" + "="*70)
print("ğŸ‰ ì „ì²´ ìˆ˜ì§‘ ì™„ë£Œ!")
print("="*70)
print("\nğŸ“ ìƒì„±ëœ íŒŒì¼:")
for year in years:
    print(f"  - data/github_{year}.csv")