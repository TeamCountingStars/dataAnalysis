import requests
import pandas as pd
import time
from datetime import datetime, timedelta
import os

class GitHubCollector:
    def __init__(self, token):
        self.token = token
        self.headers = {
            "Authorization": f"Bearer {token}",
            "Accept": "application/vnd.github+json"
        }
        self.base_url = "https://api.github.com"
    
    def check_rate_limit(self):
        url = f"{self.base_url}/rate_limit"
        response = requests.get(url, headers=self.headers)
        data = response.json()
        
        remaining = data['rate']['remaining']
        limit = data['rate']['limit']
        reset_time = datetime.fromtimestamp(data['rate']['reset'])
        
        print(f"â±ï¸  ë‚¨ì€ ìš”ì²­: {remaining}/{limit} (ë¦¬ì…‹: {reset_time.strftime('%H:%M:%S')})")
        return remaining
    
    def search_repos(self, keyword, start_date, end_date, per_page=100):
        url = f"{self.base_url}/search/repositories"
        query = f"{keyword} created:{start_date}..{end_date}"
        
        params = {
            "q": query,
            "per_page": per_page,
            "sort": "stars",
            "order": "desc",
            "page": 1
        }
        
        all_repos = []
        
        while True:
            response = requests.get(url, headers=self.headers, params=params)
            
            if response.status_code != 200:
                print(f"âŒ ì—ëŸ¬: {response.status_code}")
                break
            
            data = response.json()
            repos = data.get('items', [])
            
            if not repos:
                break
            
            all_repos.extend(repos)
            
            # 1000ê°œ ì œí•œ
            if len(all_repos) >= 1000 or params['page'] >= 10:
                break
            
            params['page'] += 1
            time.sleep(0.5)  # ì†ë„ í–¥ìƒ
        
        return all_repos
    
    def collect_by_days(self, keyword, start_date, end_date):
        """ì¼ë³„ë¡œ ë°ì´í„° ìˆ˜ì§‘"""
        all_repos = []
        
        # ë‚ ì§œ íŒŒì‹±
        start = datetime.strptime(start_date, "%Y-%m-%d")
        end = datetime.strptime(end_date, "%Y-%m-%d")
        
        total_days = (end - start).days + 1
        current_day = 0
        
        print("\n" + "="*70)
        print(f"ğŸ“… ì¼ë³„ ìˆ˜ì§‘ ì‹œì‘: {start_date} ~ {end_date} (ì´ {total_days}ì¼)")
        print("="*70)
        
        current_date = start
        while current_date <= end:
            current_day += 1
            date_str = current_date.strftime("%Y-%m-%d")
            
            print(f"\n[{current_day}/{total_days}] ğŸ” {date_str} ", end="")
            
            repos = self.search_repos(keyword, date_str, date_str)
            all_repos.extend(repos)
            
            print(f"â†’ {len(repos)}ê°œ ìˆ˜ì§‘ (ëˆ„ì : {len(all_repos)}ê°œ)")
            
            # Rate Limit ì²´í¬ (100ê°œ ë¯¸ë§Œì´ë©´ ëŒ€ê¸°)
            remaining = self.check_rate_limit()
            if remaining < 100:
                print("â¸ï¸  API ì œí•œ ì„ë°•. 1ë¶„ ëŒ€ê¸° ì¤‘...")
                time.sleep(60)
            
            current_date += timedelta(days=1)
        
        print("\n" + "="*70)
        print(f"ğŸ‰ ìˆ˜ì§‘ ì™„ë£Œ: ì´ {len(all_repos)}ê°œ (ì¤‘ë³µ í¬í•¨)")
        print("="*70)
        
        return all_repos
    
    def repos_to_dataframe(self, repos):
        """ë ˆí¬ì§€í† ë¦¬ ë¦¬ìŠ¤íŠ¸ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜ (ì¤‘ë³µ ì œê±° ì•ˆí•¨)"""
        data = []
        
        for repo in repos:
            data.append({
                'id': repo['id'],
                'name': repo['name'],
                'full_name': repo['full_name'],
                'owner': repo['owner']['login'],
                'owner_type': repo['owner']['type'],  # User or Organization
                'description': repo.get('description', ''),
                'language': repo.get('language', 'Unknown'),
                'stars': repo['stargazers_count'],
                'forks': repo['forks_count'],
                'watchers': repo['watchers_count'],
                'open_issues': repo['open_issues_count'],
                'created_at': repo['created_at'],
                'updated_at': repo['updated_at'],
                'pushed_at': repo['pushed_at'],
                'size': repo['size'],
                'url': repo['html_url'],
                'topics': '|'.join(repo.get('topics', [])),  # ì‰¼í‘œ ëŒ€ì‹  | ì‚¬ìš©
                'license': repo['license']['name'] if repo.get('license') else 'No License',
                'default_branch': repo.get('default_branch', 'main'),
                'has_wiki': repo.get('has_wiki', False),
                'has_pages': repo.get('has_pages', False),
                'archived': repo.get('archived', False)
            })
        
        df = pd.DataFrame(data)
        
        print(f"\nğŸ“Š DataFrame ìƒì„± ì™„ë£Œ: {len(df)}ê°œ ë ˆì½”ë“œ")
        return df
    
    def save_to_csv(self, df, filename):
        """CSVë¡œ ì €ì¥ (ë‹¤ìš´ë¡œë“œ ê°€ëŠ¥)"""
        if not os.path.exists('data'):
            os.makedirs('data')
        
        filepath = os.path.join('data', filename)
        df.to_csv(filepath, index=False, encoding='utf-8-sig')
        
        file_size = os.path.getsize(filepath) / 1024 / 1024  # MB
        
        print(f"\nğŸ’¾ ì €ì¥ ì™„ë£Œ!")
        print(f"ğŸ“ ê²½ë¡œ: {os.path.abspath(filepath)}")
        print(f"ğŸ“Š í¬ê¸°: {file_size:.2f} MB")
        print(f"ğŸ“‹ ë ˆì½”ë“œ: {len(df)}ê°œ")
        
        return filepath


# ========== ì‹¤í–‰ ==========

collector = GitHubCollector("í† í°ì„_ì—¬ê¸°ì—_ì…ë ¥í•˜ì„¸ìš”")

# ì´ˆê¸° Rate Limit í™•ì¸
collector.check_rate_limit()

# 2023ë…„ 1ì›” ë°ì´í„° ìˆ˜ì§‘ (í…ŒìŠ¤íŠ¸)
print("\nâš ï¸  í…ŒìŠ¤íŠ¸: 2023ë…„ 1ì›”ë§Œ ìˆ˜ì§‘í•©ë‹ˆë‹¤")
print("ì „ì²´ 2023ë…„ ìˆ˜ì§‘ì€ ì•½ 1-2ì‹œê°„ ì†Œìš” ì˜ˆìƒ")

repos = collector.collect_by_days(
    keyword="chatgpt",
    start_date="2023-01-01",
    end_date="2023-01-31"  # 1ì›”ë§Œ (31ì¼)
)

# DataFrame ë³€í™˜
df = collector.repos_to_dataframe(repos)

# ê¸°ë³¸ í†µê³„
print("\n" + "="*70)
print("ğŸ“Š ìˆ˜ì§‘ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°")
print("="*70)
print(f"\nì „ì²´ ë ˆì½”ë“œ: {len(df)}ê°œ")
print(f"ì¤‘ë³µ í¬í•¨ ë ˆì½”ë“œ: {len(df)}ê°œ")
print(f"ê³ ìœ  ë ˆí¬ì§€í† ë¦¬: {df['id'].nunique()}ê°œ")
print(f"\nì–¸ì–´ë³„ ë¶„í¬ (Top 10):")
print(df['language'].value_counts().head(10))

print(f"\nìƒìœ„ 5ê°œ ë ˆí¬:")
print(df[['name', 'stars', 'language', 'created_at']].head())

# CSV ì €ì¥ (ì›ë³¸ - ì¤‘ë³µ í¬í•¨)
collector.save_to_csv(df, 'github_chatgpt_2023_01_raw.csv')

print("\n" + "="*70)
print("âœ… 1ì›” ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ!")
print("="*70)
print("\nğŸ’¡ ë‹¤ìŒ ë‹¨ê³„:")
print("  1. ì´ ì½”ë“œê°€ ì˜ ì‘ë™í•˜ë©´ ì „ì²´ 2023ë…„ ìˆ˜ì§‘")
print("  2. ì¤‘ë³µ ì œê±°ëŠ” ì „ì²˜ë¦¬ ë‹¨ê³„ì—ì„œ ì§„í–‰")
print("  3. CSV íŒŒì¼ì„ ì¹œêµ¬ë“¤ì—ê²Œ ê³µìœ ")